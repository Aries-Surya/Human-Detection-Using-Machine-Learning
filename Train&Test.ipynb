{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d6478fb-34d8-4b43-b158-acf110e834ed",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# **Human-Detection-Using-Machine-Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ff07d4-bcfb-429b-bdd6-8d763d6a01a5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Train the model using YOLO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef360151-947a-442d-b456-8b0cdff016ee",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the model using data sets\n",
    "from ultralytics import YOLO\n",
    "# Load model\n",
    "model = YOLO('model/yolo11x-obb.pt')  # Choose a model variant\n",
    "# Train the model\n",
    "train_results = model.train(\n",
    "    data=r\"data-sets/data-sets-oob/data.yaml\",\n",
    "    epochs=15,\n",
    "    imgsz=416,  # Reduce size for faster CPU training\n",
    "    device=\"cpu\",\n",
    "    workers=3  # workers = (CPU cores / 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f02f9d6-2f91-43a3-9ed3-45810042658c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using data sets\n",
    "from ultralytics import YOLO\n",
    "# Load model\n",
    "model = YOLO('model/yolo11x-obb.pt')  # Choose a model variant\n",
    "# Train the model\n",
    "train_results = model.train(\n",
    "    data=r\"data-sets/data-sets-oob/data.yaml\",\n",
    "    epochs=50,  # Increased for better convergence\n",
    "    imgsz=640,  # Larger images improve detection accuracy\n",
    "    device=\"cpu\",  # Running on CPU\n",
    "    workers=4,  # Adjusted for better data loading on CPU\n",
    "    batch=4,  # Reduce batch size for CPU efficiency\n",
    "    augment=True,  # Enable data augmentation\n",
    "    lr0=0.0005,  # Lower initial learning rate for stable training\n",
    "    patience=10,  # Stops training if no improvement after 10 epochs\n",
    "    optimizer=\"AdamW\"  # AdamW optimizer for better weight updates\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242e6c41-2e55-4944-9115-18a9fbfcca11",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Test trained model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da38372-63d9-4d3c-a176-8351fa6ad7e2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Image testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa83353c-6467-4a2b-b48e-605fe79bee79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "# Load a model\n",
    "model = YOLO(\"runs/obb/train/weights/best.pt\")\n",
    "# Perform object detection on an image\n",
    "results = model.predict(source=\"Input/Pic\", save=True, project=\"Output/img\")\n",
    "# results[0].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c12d5d-dc57-43e7-9365-71ef4cdc947c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Video testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9f3e30-517a-4263-872e-f7564db2f196",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "# Load the trained YOLO model\n",
    "model = YOLO(\"runs/obb/train/weights/best.pt\")\n",
    "# Run inference on the video\n",
    "results = model.predict(source=\"Input/Vid/Input.mp4\", save=True, save_crop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35cc2f5-7733-4bcc-adc0-188cb8f0951b",
   "metadata": {},
   "source": [
    "## Output Rendering of Video's\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d098810-7636-47c9-9ce7-701c02f46f8f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Normal Display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813a0232-c82d-4eb3-9bee-12aa2275d3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Load the trained YOLO model\n",
    "model = YOLO(r\"runs/obb/train/weights/best.pt\")\n",
    "\n",
    "# Input video path\n",
    "video_path = \"Input/Vid/Input.mp4\"\n",
    "\n",
    "# Extract video name without extension\n",
    "video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "\n",
    "# Define output path with modified filename\n",
    "output_video_path = f\"Output/vid/{video_name}-Detected.mp4\"\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Get video properties\n",
    "frame_width = 1280  # Force resolution to 1080p width\n",
    "frame_height = 720  # Force resolution to 720p height\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))  # Get FPS from original video\n",
    "\n",
    "# Create a VideoWriter object to save output\n",
    "out = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break  # Stop if the video ends\n",
    "\n",
    "    # Resize the frame to 1080x720 to ensure consistency\n",
    "    frame_resized = cv2.resize(frame, (frame_width, frame_height))  \n",
    "\n",
    "    # Run YOLOv8 on the frame\n",
    "    results = model(frame_resized)\n",
    "\n",
    "    # Get the output frame with detections\n",
    "    annotated_frame = results[0].plot()\n",
    "\n",
    "    # Write frame to output video\n",
    "    out.write(annotated_frame)\n",
    "\n",
    "    # Show frame (optional)\n",
    "    cv2.imshow(\"YOLOv8 Detection\", annotated_frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # Press 'q' to exit\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Detection completed! Output saved as: {output_video_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0eadd94-f7fb-482d-bd40-34469834662b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Live Webcam Detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b4fccd-3bb2-4e4a-a24a-97da38062b99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Paths\n",
    "model_path = r'runs/detect/train/weights/best.pt'  # Adjust based on your trained model path\n",
    "output_folder = r'Output'\n",
    "\n",
    "# Create output folder if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Load the trained model\n",
    "model = YOLO(model_path)\n",
    "\n",
    "# **Use Live Webcam Feed**\n",
    "video_source = 0  # 0 for default webcam, 1 for external webcam\n",
    "\n",
    "# Open video capture\n",
    "cap = cv2.VideoCapture(video_source)\n",
    "\n",
    "# Check if the webcam opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(f\"Error: Could not access webcam\")\n",
    "    exit()\n",
    "\n",
    "# Get video properties\n",
    "fps = cap.get(cv2.CAP_PROP_FPS) or 30  # Default to 30 FPS if FPS is unavailable\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Set output video filename dynamically\n",
    "output_video_name = \"Webcam-Detected.mp4\"\n",
    "output_video_path = os.path.join(output_folder, output_video_name)\n",
    "\n",
    "# Initialize VideoWriter\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for MP4\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "frame_number = 0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Error: Failed to capture frame from webcam.\")\n",
    "        break\n",
    "\n",
    "    # Perform inference\n",
    "    results = model.predict(source=frame)\n",
    "\n",
    "    # Process results\n",
    "    annotated_frame = False  # Flag to track if any person was detected\n",
    "\n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        names = result.names\n",
    "\n",
    "        if boxes is not None:\n",
    "            for box in boxes:\n",
    "                x1, y1, x2, y2 = box.xyxy[0].tolist()  # Get bounding box coordinates\n",
    "                cls = int(box.cls[0])  # Get class index\n",
    "                conf = box.conf[0]  # Get confidence score\n",
    "                label = names[cls]\n",
    "\n",
    "                if label == 'person' and conf >= 0.3:  # Check if detected object is a person\n",
    "                    annotated_frame = True  # Set flag to True\n",
    "\n",
    "                    # Draw bounding boxes and labels\n",
    "                    cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "                    cv2.putText(frame, f'{label} {conf:.2f}', (int(x1), int(y1) - 10), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    if annotated_frame:\n",
    "        # Write the annotated frame to the video file\n",
    "        out.write(frame)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('YOLO Live Detection', frame)\n",
    "\n",
    "    # Press 'q' to quit the video loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    frame_number += 1\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f'âœ… Annotated live webcam video saved at: {output_video_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
